---
layout: post
title: MongoDB와 로그스태시
summary: 열심히 기록하자!
author: Lee Chang Ho
date: '2021-06-13 22:50:00'
category: 프로젝트
published: true
image:  mongo/logo.png
tags:   MongoDB Logstash
---

## MongoDB의 데이터를 Logstash로 가져오기
###### 현재 진행중인 프로젝트에서 MongoDB의 데이터를 가져와 ElasticSearch에 색인을 해야 한다.
###### 기존의 MySQL의 경우 JDBC Plugin을 통해 색인을 진행하였지만 MongoDB의 경우 ElasticSearch에서 지원하는 공식 Input Plugin이 없다고 한다.  
###### MongoDB의 데이터를 Logstash로 가져오기 위해서는 아래 2가지 방법이 존재하는 듯 한다.
- logstash-input-mongodb
- Jdbc(MongoDB jar)
###### 위의 두가지 방법 중 첫번째 방법인 logstash-input-mongodb를 설치하여 진행을 해 보자

---
#### logstash-input-mongodb Install
--- 
###### 해당 플러그인의 경우 공식 플러그인이 아닌 뛰어난 능력자가 만들어 놓은 플러그인이다. 그래서 Logstash의 기본 플러그인에 설치가 되어 있지 않기 때문에 따로 설치를 진행하여야 한다.  
###### 아래 명령어를 이용하여 설치를 진행한다.
- logstash-plugin.bat install logstash-input-mongodb
- logstash-plugin.bat install logstash-output-mongodb
![이미지]({{ site.url }}/images/mongo/Plugin설치.png)
###### 방금 설치한 플러그인은 input과 output 모두를 설치하였다. (output은 필요없지만)

---
#### logstash 셋팅
--- 
###### 필자의 경우 미리 Mongodb를 설치하여 test란 DB를 만들고 test_data라는 컬렉션도 생성하였다.  그리고 데이터도 미리 넣어 둔 상태이다.  

```
input {    
    mongodb {
		uri => 'mongodb://localhost:27017/test'
		placeholder_db_dir => '../'
		placeholder_db_name => 'logstash_sqlite.test'
		collection => 'test_data'
		batch_size => 5000
		generateId => false
		parse_method => "simple"
	}
}
output {
	stdout {        
        codec => rubydebug    
    }
}
```

---
#### logstash 실행
--- 
```
.\bin\logstash.bat -f .\config\mogo-logstash.conf
```
###### 위의 명령어로 로그스태시를 실행한다. 
###### 그럼 아래와 같이 Cmd 창에 MongoDB의 데이터가 출력이 될 것이다.  
```
[2021-06-13T22:45:29,130][INFO ][logstash.agent           ] Pipelines running {:count=>2, :running_pipelines=>[:".monitoring-logstash", :main], :non_running_pipelines=>[]}
{
      "firstName" => "BBBB",
       "@version" => "1",
           "host" => "DESKTOP-S52QU7L",
            "_id" => "60c607d98dcccf4864f403be",
         "userId" => 2,
     "@timestamp" => 2021-06-13T13:45:29.191Z,
       "lastName" => "h5jdd",
       "homepage" => "https://amogg.tistory.com/2",
       "mongo_id" => "60c607d98dcccf4864f403be",
        "logdate" => "2021-06-13T13:27:53+00:00",
    "phoneNumber" => "123456",
      "log_entry" => "{\"_id\"=>BSON::ObjectId('60c607d98dcccf4864f403be'), \"userId\"=>2, \"firstName\"=>\"BBBB\", \"lastName\"=>\"h5jdd\", \"phoneNumber\"=>\"123456\", \"homepage\"=>\"https://amogg.tistory.com/2\"}"
}
...
{
      "firstName" => "EEEEE",
       "@version" => "1",
           "host" => "DESKTOP-S52QU7L",
            "_id" => "60c607d98dcccf4864f403c7",
         "userId" => 5,
     "@timestamp" => 2021-06-13T13:45:29.230Z,
       "lastName" => "asdfasdf",
       "homepage" => "https://amogg.tistory.com/5",
       "mongo_id" => "60c607d98dcccf4864f403c7",
        "logdate" => "2021-06-13T13:27:53+00:00",
    "phoneNumber" => "111111111",
      "log_entry" => "{\"_id\"=>BSON::ObjectId('60c607d98dcccf4864f403c7'), \"userId\"=>5, \"firstName\"=>\"EEEEE\", \"lastName\"=>\"asdfasdf\", \"phoneNumber\"=>\"111111111\", \"homepage\"=>\"https://amogg.tistory.com/5\"}"
}
[2021-06-13T22:45:29,996][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
```

###### 정상적으로 데이터를 읽어오고 있다! 성공!!  
###### 여기서 드는 의문은 보통 검색엔진의 경우 전체색인과 증분색인의 개념이 있다.  
- 전체색인 : 전체 데이터를 색인한다.
- 증분색인 : 특정 시점을 기준으로 새로운 이벤트(삽입,수정,삭제 등)가 발생한 데이터만 색인한다.

###### 기존의 jdbc 플러그인을 통해 데이터를 가져올 경우 tracking_column이라는 옵션을 이용해 증분데이터를 색인하였다.  
###### 일단 데이터를 하나 추가해보자  
```
[2021-06-13T22:45:29,996][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
{
      "firstName" => "GGGGGG",
       "@version" => "1",
           "host" => "DESKTOP-S52QU7L",
            "_id" => "60c6121f8dcccf4864f409e3",
         "userId" => 7,
     "@timestamp" => 2021-06-13T14:11:47.549Z,
       "lastName" => "asdfasdf",
       "homepage" => "https://amogg.tistory.com/5",
       "mongo_id" => "60c6121f8dcccf4864f409e3",
        "logdate" => "2021-06-13T14:11:43+00:00",
    "phoneNumber" => "GGGGG",
      "log_entry" => "{\"_id\"=>BSON::ObjectId('60c6121f8dcccf4864f409e3'), \"userId\"=>7, \"firstName\"=>\"GGGGGG\", \"lastName\"=>\"asdfasdf\", \"phoneNumber\"=>\"GGGGG\", \"homepage\"=>\"https://amogg.tistory.com/5\"}"
}
```
###### 새로 추가 된 데이터가 바로 출력이 된다. 옵션을 다시 살펴보면 placeholder_db_dir, placeholder_db_name 이라는 옵션이 존재하는데 여기서 placeholder_db_name 필드가 MongoDB와 로그스태시의 Sync를 맞춰주는 옵션이다. 해당 파일을 열면 알수없는 문자들이 들어있지만 추정해보면 어디까지 로그스태시가 읽었는지에 대한 데이터가 보관되어 있을 것이다.  
###### 확인을 위해서는 테스트를 해보자.  
###### 테스트 방법은 이렇다. 로그스태시를 중지한 뒤 다시 실행을 시켜보고 만약 데이터를 읽어 오지 않는 다면 placeholder_db_name 파일을 삭제를 한 뒤 다시 실행을 시켜본다.  

<!--stackedit_data:
eyJoaXN0b3J5IjpbNTcwNTY2MTkxLC02OTQ4MTU0NTUsMTIyMD
MzODI2Ml19
-->